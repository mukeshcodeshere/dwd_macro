{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro research\n",
    "## Quantifying geopolitical uncertainty that isn’t yet reflected in the markets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  The world is currently experiencing more conflicts than at any time since the post-9/11 Iraq war.\n",
    "-  I believe the risk of nuclear war is at its highest level since the Cold War.\n",
    "-  Despite these risks, the S&P 500 keeps reaching new highs, driven by the ChatGPT initiated tech boom.\n",
    "-  Markets seem aware of war risks, as shown by Bitcoin's quick drop when Iran attacked Israel with war drones. S&P 500 did not reflect this drop as it was a Sunday.\n",
    "-  This leads me to believe that that markets believe AI's economic benefits outweigh the potential negative impacts of war.\n",
    "-  This study aims to:\n",
    "  1. Measure the positive effects of AI and negative effects of war on the economy\n",
    "  2. Analyze how these 2 factors are currently priced into markets\n",
    "  3. Compare the current situations with the 2000 tech boom and Cold War era to identify possible future scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses\n",
    "\n",
    "1. **AI's Economic Impact vs. War Risks**  \n",
    "   Hypothesis: The S&P 500 and other global indices are more influenced by AI-driven growth trends than by geopolitical risks such as conflicts or war.\n",
    "\n",
    "   - Test: Analyze correlations between AI-driven tech indices (e.g., NASDAQ Composite or specific AI-related ETFs) and macroeconomic indicators (e.g., GDP, unemployment). Compare these correlations during different periods of conflict.\n",
    "\n",
    "2. **Bitcoin as a Geopolitical Risk Barometer**  \n",
    "   Hypothesis: Bitcoin responds more rapidly to geopolitical tensions compared to traditional equity indices due to its decentralized nature.\n",
    "\n",
    "   - Test: Analyze intraday price movements of Bitcoin and compare them to the S&P 500 during major geopolitical events, such as the Iran-Israel drone attack.\n",
    "\n",
    "3. **Market Resilience During Conflict**  \n",
    "   Hypothesis: The current resilience of the S&P 500 to geopolitical shocks is comparable to market behavior during the Cold War and the 2000 Tech Boom, suggesting that technological optimism outweighs geopolitical fears.\n",
    "\n",
    "   - Test: Compare volatility indices (e.g., VIX) and treasury yields during key geopolitical tensions across the Cold War, 2000 Tech Boom, and post-2022 AI boom.\n",
    "\n",
    "4. **Geopolitical Risk Premium in Fixed Income**  \n",
    "   Hypothesis: Treasury yields reflect a greater sensitivity to geopolitical risks compared to equity indices, acting as a haven during periods of heightened tensions.\n",
    "\n",
    "   - Test: Compare movements in 10-year and 30-year Treasury yields during major geopolitical events with equity indices' performance.\n",
    "\n",
    "5. **Liquidity Indicators and War Risks**  \n",
    "   Hypothesis: Increased liquidity injections by central banks during geopolitical crises stabilize markets, reducing immediate impacts of conflict-related news.\n",
    "\n",
    "   - Test: Compare changes in the Federal Reserve Balance Sheet (WALCL) and Overnight Reverse Repo Agreements (RRPONTSYD) during major conflicts.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Time Period Analysis**  \n",
    "   Segment the dataset into the predefined periods:  \n",
    "   - Post-2022 AI Tech Boom  \n",
    "   - Cold War  \n",
    "   - 2000 Tech Boom  \n",
    "\n",
    "   Use these periods to analyze how macroeconomic indicators, equity indices, and fixed-income instruments responded to technological trends and geopolitical risks.\n",
    "\n",
    "2. **Volatility and Sensitivity Analysis**  \n",
    "   - Use historical daily returns for indices (`df_yahoo_returns`) to calculate rolling volatilities during conflict periods.  \n",
    "   - Apply event studies to assess market reactions to major geopolitical events.\n",
    "\n",
    "3. **Regression Analysis**  \n",
    "   - Use equity returns (e.g., S&P 500) as the dependent variable and macro indicators (e.g., treasury spreads, inflation, GDP) as independent variables.  \n",
    "   - Add dummy variables for conflict events to measure their incremental impact.\n",
    "\n",
    "4. **Scenario Comparisons**  \n",
    "   - Compare Sharpe ratios, volatility, and drawdowns for indices across the three periods.  \n",
    "   - Evaluate how liquidity measures and stress indices (e.g., STLFSI) varied during high-conflict periods.\n",
    "\n",
    "5. **Correlation Analysis**  \n",
    "   - Assess correlations between Bitcoin and equity indices during geopolitical events.  \n",
    "   - Compare correlations of growth indicators (e.g., GDP) with equity indices across periods.\n",
    "\n",
    "6. **Visualizations**  \n",
    "   - Plot historical returns with time-period-specific shading using `time_period_colors` for intuitive comparison.  \n",
    "   - Overlay macroeconomic indicators like treasury yields, volatility (VIX), and Bitcoin prices on the same timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to add implied vol options data predicions on spy for forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNLOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for S&P 500 (^GSPC)\n",
      "Fetched data for Nikkei 225 (^N225)\n",
      "Fetched data for FTSE 100 (^FTSE)\n",
      "Fetched data for Hang Seng Index (^HSI)\n",
      "Fetched data for Hang Seng Index (^IXIC)\n",
      "Fetched data for 10-Year Treasury Yield (^TNX)\n",
      "Fetched data for 30-Year Treasury Yield (^TYX)\n",
      "Fetched data for 5-Year Treasury Yield (^FVX)\n",
      "Fetched data for 13-Week Treasury Bill Yield (^IRX)\n",
      "Fetched data for CBOE Volatility Index (^VIX)\n",
      "Fetched data for Bitcoin_USD (BTC-USD)\n",
      "Fetched data for Gross Domestic Product (GDP)\n",
      "Fetched data for Unemployment Rate (UNRATE)\n",
      "Fetched data for Industrial Production (INDPRO)\n",
      "Fetched data for Nonfarm Payrolls (PAYEMS)\n",
      "Fetched data for Labor Force Participation Rate (CIVPART)\n",
      "Fetched data for Consumer Price Index (CPIAUCSL)\n",
      "Fetched data for Producer Price Index (PPIACO)\n",
      "Fetched data for Core PCE Price Index (PCEPILFE)\n",
      "Fetched data for Trade Balance (BOPGSTB)\n",
      "Fetched data for US Dollar Index (DTWEXBGS)\n",
      "Fetched data for Federal Funds Rate (FEDFUNDS)\n",
      "Fetched data for 10-Year Treasury Minus 2-Year Treasury Spread (T10Y2Y)\n",
      "Fetched data for Moody’s BAA Corporate Bond Yield Spread (BAA10Y)\n",
      "Fetched data for St. Louis Fed Financial Stress Index (STLFSI)\n",
      "Fetched data for Federal Reserve Balance Sheet (WALCL)\n",
      "Fetched data for M1 Money Stock (M1SL)\n",
      "Fetched data for M2 Money Stock (M2SL)\n",
      "Fetched data for Overnight Reverse Repo Agreements (RRPONTSYD)\n",
      "Fetched data for Total Assets, Liquidity Facilities (TOTALSL)\n",
      "Fetched data for Effective Federal Funds Rate (DFF)\n",
      "Timezone-naive index detected. Ensuring it's converted to a valid datetime.\n",
      "Timezone-naive datetime detected.\n",
      "Index is not datetime, converting to naive datetime.\n",
      "Index is not datetime, converting to naive datetime.\n",
      "Event date 2023-10-01 00:00:00 not found. Using closest available date: 2023-10-02 00:00:00\n",
      "Bitcoin event-driven change:  -237.12244866337443\n",
      "Event date 2023-10-01 00:00:00 not found. Using closest available date: 2023-10-02 00:00:00\n",
      "S&P 500 event-driven change:  13137.146347912394\n",
      "Correlation between Bitcoin and S&P 500 during the event: 0.28568074166124896\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "from fredapi import Fred\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Yahoo Finance and FRED tickers\n",
    "yahoo_tickers = {\n",
    "    # Equity Indices\n",
    "    \"^GSPC\": \"S&P 500\",\n",
    "    \"^N225\": \"Nikkei 225\",\n",
    "    \"^FTSE\": \"FTSE 100\",\n",
    "    \"^HSI\": \"Hang Seng Index\",\n",
    "    \"^IXIC\": \"Hang Seng Index\",\n",
    "\n",
    "    # Fixed Income\n",
    "    \"^TNX\": \"10-Year Treasury Yield\",\n",
    "    \"^TYX\": \"30-Year Treasury Yield\",\n",
    "    \"^FVX\": \"5-Year Treasury Yield\",\n",
    "    \"^IRX\": \"13-Week Treasury Bill Yield\",\n",
    "\n",
    "    # Volatility\n",
    "    \"^VIX\": \"CBOE Volatility Index\",\n",
    "\n",
    "    # Crypto\n",
    "    \"BTC-USD\": \"Bitcoin_USD\",\n",
    "}\n",
    "\n",
    "fred_series = {\n",
    "    # Growth and Employment\n",
    "    'GDP': 'Gross Domestic Product',\n",
    "    'UNRATE': 'Unemployment Rate',\n",
    "    'INDPRO': 'Industrial Production',\n",
    "    'PAYEMS': 'Nonfarm Payrolls',\n",
    "    'CIVPART': 'Labor Force Participation Rate',\n",
    "\n",
    "    # Inflation and Prices\n",
    "    'CPIAUCSL': 'Consumer Price Index',\n",
    "    'PPIACO': 'Producer Price Index',\n",
    "    'PCEPILFE': 'Core PCE Price Index',\n",
    "\n",
    "    # Trade and Globalization\n",
    "    'BOPGSTB': 'Trade Balance',\n",
    "    'DTWEXBGS': 'US Dollar Index',\n",
    "\n",
    "    # Financial Conditions\n",
    "    'FEDFUNDS': 'Federal Funds Rate',\n",
    "    'T10Y2Y': '10-Year Treasury Minus 2-Year Treasury Spread',\n",
    "    'BAA10Y': 'Moody’s BAA Corporate Bond Yield Spread',\n",
    "    'STLFSI': 'St. Louis Fed Financial Stress Index',\n",
    "    \n",
    "    # Liquidity Indicators\n",
    "    'WALCL': 'Federal Reserve Balance Sheet',\n",
    "    'M1SL': 'M1 Money Stock', # NARROW\n",
    "    'M2SL': 'M2 Money Stock',\n",
    "    'RRPONTSYD': 'Overnight Reverse Repo Agreements',\n",
    "    'TOTALSL': 'Total Assets, Liquidity Facilities',\n",
    "    'DFF': 'Effective Federal Funds Rate'\n",
    "}\n",
    "\n",
    "# Initialize data containers\n",
    "yahoo_data = {}\n",
    "fred_data = {}\n",
    "\n",
    "# Fetch data from Yahoo Finance\n",
    "for ticker, name in yahoo_tickers.items():\n",
    "    try:\n",
    "        data = Ticker(ticker)\n",
    "        history = data.history(period=\"max\")\n",
    "        if not history.empty:  # Ensure data exists for the ticker\n",
    "            history['Ticker'] = ticker\n",
    "            history['Name'] = name\n",
    "            yahoo_data[ticker] = history\n",
    "            print(f\"Fetched data for {name} ({ticker})\")\n",
    "        else:\n",
    "            print(f\"No data for {name} ({ticker})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {name} ({ticker}): {e}\")\n",
    "\n",
    "# Fetch data from FRED API (ensure you replace the API key with your own)\n",
    "fred_api_key = os.getenv('FRED_API_KEY')  # Replace with your FRED API key or set it as an environment variable\n",
    "fred = Fred(api_key=fred_api_key)\n",
    "\n",
    "for series_id, series_name in fred_series.items():\n",
    "    try:\n",
    "        series_data = fred.get_series(series_id)\n",
    "        if series_data is not None and not series_data.empty:  # Ensure data exists for the series\n",
    "            series_df = pd.DataFrame(series_data, columns=['Value'])\n",
    "            series_df['Ticker'] = series_id\n",
    "            series_df['Name'] = series_name\n",
    "            fred_data[series_id] = series_df\n",
    "            print(f\"Fetched data for {series_name} ({series_id})\")\n",
    "        else:\n",
    "            print(f\"No data for {series_name} ({series_id})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {series_name} ({series_id}): {e}\")\n",
    "\n",
    "# Define time periods and their corresponding colors\n",
    "time_periods = {\n",
    "    \"Post-2022 AI Tech Boom\": (\"2022-01-01\", \"2025-01-01\"),\n",
    "    \"Cold War\": (\"1947-01-01\", \"1991-12-31\"),\n",
    "    \"2000 Tech Boom\": (\"1995-01-01\", \"2002-12-31\")\n",
    "}\n",
    "time_period_colors = {\n",
    "    \"Post-2022 AI Tech Boom\": \"lightblue\",\n",
    "    \"Cold War\": \"lightgreen\",\n",
    "    \"2000 Tech Boom\": \"lightcoral\"\n",
    "}\n",
    "\n",
    "# Combine Yahoo Finance data into a single DataFrame and save to CSV\n",
    "if yahoo_data:\n",
    "    df_yahoo = pd.concat(yahoo_data.values(), ignore_index=False)\n",
    "    df_yahoo.reset_index(inplace=True)\n",
    "    df_yahoo.to_csv('yahoo_data.csv', index=False)\n",
    "else:\n",
    "    print(\"No Yahoo Finance data to save.\")\n",
    "\n",
    "# Combine FRED data into a single DataFrame and save to CSV\n",
    "if fred_data:\n",
    "    df_fred = pd.concat(fred_data.values(), ignore_index=False)\n",
    "    df_fred.reset_index(inplace=True)\n",
    "    df_fred.rename(columns={\"index\":\"date\"}, inplace=True)\n",
    "    df_fred.to_csv('fred_data.csv', index=False)\n",
    "else:\n",
    "    print(\"No FRED data to save.\")\n",
    "\n",
    "# Set 'date' as index for easier manipulation\n",
    "df_yahoo.set_index('date', inplace=True)\n",
    "df_fred.set_index('date', inplace=True)\n",
    "\n",
    "# Calculate daily returns for each ticker in df_yahoo (using 'adjclose' column)\n",
    "tickers_yahoo = df_yahoo['Ticker'].unique()\n",
    "tickers_fred = df_fred['Ticker'].unique()\n",
    "\n",
    "# Exclude fixed-income yield tickers for returns calculations\n",
    "exclude_tickers = ['^TNX', '^TYX', \"^FVX\", \"^IRX\"]  # Exclude Treasury yields from returns calculations\n",
    "\n",
    "# Initialize an empty DataFrame for returns\n",
    "df_yahoo_returns = pd.DataFrame()\n",
    "\n",
    "# Loop through tickers_yahoo (the list of tickers you want to process)\n",
    "for ticker in tickers_yahoo:\n",
    "    if ticker not in exclude_tickers:  # Only include tickers that are not in the exclude list\n",
    "        # Filter the dataframe for the current ticker\n",
    "        ticker_data = df_yahoo[df_yahoo['symbol'] == ticker]\n",
    "        \n",
    "        # Calculate percentage change for adjusted close prices and drop NaNs\n",
    "        df_yahoo_returns[ticker] = ticker_data['adjclose'].pct_change().dropna()\n",
    "\n",
    "def date_filter(df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Filter a DataFrame by the given date range.\n",
    "    Assumes the index is a datetime index.\n",
    "    \"\"\"\n",
    "    return df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "def ensure_datetime_index(df):\n",
    "    \"\"\"\n",
    "    Ensure the index is a timezone-naive datetime index.\n",
    "    If the index is timezone-aware, convert to UTC and remove the timezone.\n",
    "    If it's naive, just ensure it's a correct datetime format.\n",
    "    \"\"\"\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        if df.index.tz is not None:\n",
    "            print(\"Timezone-aware datetime detected. Converting to naive datetime.\")\n",
    "            df.index = df.index.tz_convert('UTC').tz_localize(None)\n",
    "        else:\n",
    "            print(\"Timezone-naive datetime detected.\")\n",
    "            df.index = pd.to_datetime(df.index)  # Ensure it's a valid datetime\n",
    "    else:\n",
    "        print(\"Index is not datetime, converting to naive datetime.\")\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "def handle_mixed_datetime(df):\n",
    "    \"\"\"\n",
    "    Handle mixed timezone-aware and timezone-naive datetimes in the DataFrame index.\n",
    "    Convert all datetimes to timezone-naive.\n",
    "    \"\"\"\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        if df.index.tz is not None:\n",
    "            print(\"Timezone-aware index detected. Converting to naive datetime.\")\n",
    "            df.index = df.index.tz_convert('UTC').tz_localize(None)\n",
    "        else:\n",
    "            print(\"Timezone-naive index detected. Ensuring it's converted to a valid datetime.\")\n",
    "            df.index = pd.to_datetime(df.index)  # Ensure it's valid datetime\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the data cleaning functions to your DataFrames\n",
    "df_fred = handle_mixed_datetime(df_fred)\n",
    "df_yahoo = handle_mixed_datetime(df_yahoo)\n",
    "df_yahoo_returns = handle_mixed_datetime(df_yahoo_returns)\n",
    "\n",
    "df_fred = ensure_datetime_index(df_fred)\n",
    "df_yahoo = ensure_datetime_index(df_yahoo)\n",
    "df_yahoo_returns = ensure_datetime_index(df_yahoo_returns)\n",
    "\n",
    "df_fred.dropna(inplace=True)\n",
    "\n",
    "def event_driven_change(event_date, df, column_name, days=30):\n",
    "    \"\"\"\n",
    "    Calculate the percentage change in a specified column after a given event date.\n",
    "    Tries to find the closest available date if the exact event date is not in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - event_date (pd.Timestamp): The event date.\n",
    "    - df (pd.DataFrame): DataFrame containing the data.\n",
    "    - column_name (str): The column name for which we want to calculate the percentage change.\n",
    "    - days (int): The number of days after the event to calculate the change (default is 30).\n",
    "    \n",
    "    Returns:\n",
    "    - (float): The percentage change in the value of the specified column after the given number of days.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column {column_name} does not exist in the DataFrame.\")\n",
    "    \n",
    "    # Check if the event_date is in the dataframe\n",
    "    if event_date not in df.index:\n",
    "        # Find the closest available date (nearest)\n",
    "        timedeltas = df.index - event_date\n",
    "        closest_date = df.index[(np.abs(timedeltas)).argmin()]  # Fix here: use np.abs on timedeltas\n",
    "        print(f\"Event date {event_date} not found. Using closest available date: {closest_date}\")\n",
    "        event_date = closest_date\n",
    "    \n",
    "    # Get the value on the event date for the selected column\n",
    "    value_on_event_date = df.loc[event_date, column_name]\n",
    "    \n",
    "    # Calculate the end date (30 days later)\n",
    "    end_date = event_date + pd.Timedelta(days=days)\n",
    "    \n",
    "    # Check if end_date exists in the DataFrame, if not, use the closest available date\n",
    "    if end_date not in df.index:\n",
    "        # Find the closest available end_date (bfill)\n",
    "        timedeltas = df.index - end_date\n",
    "        end_date = df.index[(np.abs(timedeltas)).argmin()]\n",
    "        print(f\"End date {end_date} not found. Using closest available date.\")\n",
    "    \n",
    "    # Get the value 30 days after the event date\n",
    "    value_30_days_later = df.loc[end_date, column_name]\n",
    "    \n",
    "    # Calculate the percentage change over 30 days\n",
    "    percentage_change = (value_30_days_later - value_on_event_date) / value_on_event_date * 100\n",
    "    return percentage_change\n",
    "\n",
    "\n",
    "# Example: Event-driven analysis for Bitcoin vs. S&P 500 during an event\n",
    "event_date = pd.Timestamp('2023-10-01')\n",
    "print(\"Bitcoin event-driven change: \", event_driven_change(event_date, df_yahoo_returns, 'BTC-USD'))\n",
    "print(\"S&P 500 event-driven change: \", event_driven_change(event_date, df_yahoo_returns, '^GSPC'))\n",
    "\n",
    "# Define correlation function for Bitcoin and S&P 500 during conflict periods\n",
    "def correlation_analysis(df_returns, ticker1, ticker2, start_date, end_date):\n",
    "    df_event = date_filter(df_returns, start_date, end_date)\n",
    "    correlation = df_event[[ticker1, ticker2]].corr().iloc[0, 1]\n",
    "    return correlation\n",
    "\n",
    "# Example: Correlation between Bitcoin and S&P 500 during a geopolitical event\n",
    "event_start_date = pd.Timestamp('2023-10-01')\n",
    "event_end_date = pd.Timestamp('2023-10-15')\n",
    "correlation_btc_sp500 = correlation_analysis(df_yahoo_returns, 'BTC-USD', '^GSPC', event_start_date, event_end_date)\n",
    "print(f\"Correlation between Bitcoin and S&P 500 during the event: {correlation_btc_sp500}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
